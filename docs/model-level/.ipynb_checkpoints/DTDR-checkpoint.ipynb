{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree/Decision Rules\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Load Data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "# Import for Split Data into Training and Testing Samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset = pd.read_csv((\"../../datasets/lucene-2.9.0.csv\"), index_col = 'File')\n",
    "test_dataset = pd.read_csv((\"../../datasets/lucene-3.0.0.csv\"), index_col = 'File')\n",
    "\n",
    "outcome = 'RealBug'\n",
    "features = ['OWN_COMMIT', 'Added_lines', 'CountClassCoupled', 'AvgLine', 'RatioCommentToCode']\n",
    "\n",
    "# process outcome to 0 and 1\n",
    "train_dataset[outcome] = pd.Categorical(train_dataset[outcome])\n",
    "train_dataset[outcome] = train_dataset[outcome].cat.codes\n",
    "\n",
    "test_dataset[outcome] = pd.Categorical(test_dataset[outcome])\n",
    "test_dataset[outcome] = test_dataset[outcome].cat.codes\n",
    "\n",
    "X_train = train_dataset.loc[:, features]\n",
    "X_test = test_dataset.loc[:, features]\n",
    "\n",
    "y_train = train_dataset.loc[:, outcome]\n",
    "y_test = test_dataset.loc[:, outcome]\n",
    "\n",
    "\n",
    "# commits - # of commits that modify the file of interest\n",
    "# Added lines - # of added lines of code\n",
    "# Count class coupled - # of classes that interact or couple with the class of interest\n",
    "# LOC - # of lines of code\n",
    "# RatioCommentToCode - The ratio of lines of comments to lines of code\n",
    "features = ['nCommit', 'AddedLOC', 'nCoupledClass', 'LOC', 'CommentToCodeRatio']\n",
    "\n",
    "X_train.columns = features\n",
    "X_test.columns = features\n",
    "training_data = pd.concat([X_train, y_train], axis=1)\n",
    "testing_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a black-box model (Regression and Random Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=10, random_state=1234)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for Construct a black-box model (Regression and Random Forests)\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# regression (ols)\n",
    "model_formula = outcome + ' ~ ' + ' + '.join(features)\n",
    "regression_model = ols(model_formula, data = training_data)\n",
    "# regression_model = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "regression_model_fit = regression_model.fit()\n",
    "\n",
    "# regression (logistic regression)\n",
    "lr_model = LogisticRegression(fit_intercept = True)\n",
    "lr_model.fit(X_train, y_train)  \n",
    "\n",
    "# random forests\n",
    "rf_model = RandomForestClassifier(random_state=1234, n_jobs = 10)\n",
    "rf_model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-release model validation for sanity check (Train with 2.9.0 and test with 3.0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance(model, X_test, y_test):\n",
    "    model_prediction = model.predict_proba(X_test.values)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, model_prediction, pos_label=1)\n",
    "    auc_value = metrics.auc(fpr, tpr)\n",
    "    transformed_prediction = [int(i >= 0.5) for i in model_prediction]\n",
    "    f1_value = metrics.f1_score(y_test, transformed_prediction)\n",
    "    return auc_value, f1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression (AUC, F1): (0.7989602095955461, 0.23236514522821577)\n",
      "Random Forests (AUC, F1): (0.8589023524916761, 0.4951456310679611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jirayusjiar/.conda/envs/xaitools/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"\"\"\n",
      "/home/jirayusjiar/.conda/envs/xaitools/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "print('Regression (AUC, F1):', get_model_performance(lr_model, X_test, y_test))\n",
    "print('Random Forests (AUC, F1):', get_model_performance(rf_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Rules/Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Decision Rules/Decision Trees\n",
    "from sklearn import tree\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- nCoupledClass <= 5.50\n",
      "|   |--- AddedLOC <= 145.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- AddedLOC >  145.50\n",
      "|   |   |--- class: 0\n",
      "|--- nCoupledClass >  5.50\n",
      "|   |--- AddedLOC <= 113.00\n",
      "|   |   |--- class: 0\n",
      "|   |--- AddedLOC >  113.00\n",
      "|   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# construct a decision rules/decision trees model\n",
    "dt_model = tree.DecisionTreeClassifier(random_state=1234, max_depth=2)\n",
    "dt_model.fit(X_train, y_train)  \n",
    "dt_text = tree.export_text(dt_model, \n",
    "                          feature_names = features)\n",
    "  \n",
    "\n",
    "# visualize \n",
    "print(dt_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaitools",
   "language": "python",
   "name": "xaitools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
