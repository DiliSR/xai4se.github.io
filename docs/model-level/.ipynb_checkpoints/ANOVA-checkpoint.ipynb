{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA analysis\n",
    "\n",
    "Analysis of Variance (a.k.a. multi-way ANOVA) is a statistical test that\n",
    "examines the importance of multiple independent variables (e.g., two or\n",
    "more software metrics) on the outcome (e.g.,\n",
    "defect-proneness) {cite}`fisher1925intraclass`. The significance of each\n",
    "metric in a regression model is estimated from the calculation of the\n",
    "Sum of Squares (SS)---i.e., the explained variance of the observations\n",
    "with respect to their mean value. There are two commonly-used approaches\n",
    "to calculate the Sum of Squares for ANOVA, namely, Type-I and Type-II.\n",
    "We provide a description of the two types of ANOVA below.\n",
    "\n",
    "**Type-I**, *one of the most commonly-used interpretation techniques and\n",
    "the default interpretation technique for a logistic regression (`glm`)\n",
    "model in R*, examines the importance of each metric in a sequential\n",
    "order [@fox2015applied; @chambers1992statistical]. In other words,\n",
    "Type-I measures the improvement of the Residual Sum of Squares (RSS)\n",
    "(i.e., the unexplained variance) when each metric is sequentially added\n",
    "into the model. Hence, Type-I attributes as much variance as it can to\n",
    "the first metric before attributing residual variance to the second\n",
    "metric in the model specification. Thus, the importance (i.e., produced\n",
    "ranking) of metrics is dependent on the ordering of metrics in the model\n",
    "specification.\n",
    "\n",
    "The calculation starts from the RSS of the preliminary model\n",
    "($y \\sim 1$), i.e., a null model that is fitted without any software\n",
    "metrics. We then compute the RSS of the first metric by fitting a\n",
    "regression model with the first metric ($y \\sim m_1$). Thus, the\n",
    "importance of the first metric ($m_1$) is the improvement between the\n",
    "unexplained variances (RSS) of the preliminary model and the model that\n",
    "is constructed by the first metric.\n",
    "\n",
    "$$\\mathrm{SS}(m_1) = \\mathrm{RSS}(\\mathrm{Model}_\\mathrm{null})-\\mathrm{RSS}(m_1)$$\n",
    "\n",
    "Similar to the computation of the importance of the first metric, the\n",
    "importance of the remaining metrics is computed using the following\n",
    "equation.\n",
    "\n",
    "$$\\mathrm{SS}(m_i) = \\mathrm{RSS}(\\mathrm{m_1 + ... + m_{i-1}})-\\mathrm{RSS}(m_1 + ... + m_i)$$\n",
    "\n",
    "**Type II**, an enhancement to the ANOVA Type-I, examines the importance\n",
    "of each metric in a hierarchical nature, i.e., the ordering of metrics\n",
    "is rearranged for each\n",
    "examination [@fox2015applied; @chambers1992statistical]. The importance\n",
    "of metrics (Type-II) measures the improvement of the Residual Sum of\n",
    "Squares (RSS) (i.e., the unexplained variance) when adding a metric\n",
    "under examination to the model after the other metrics. In other words,\n",
    "the importance of metrics (Type-II) is equivalent to a Type-I where a\n",
    "metric under examination appears at the last position of the model. The\n",
    "intuition is that the Type-II is evaluated after all of the other\n",
    "metrics have been accounted for. The importance of each metric (i.e.,\n",
    "SS($m_e$)) measures the improvement of the RSS of the model that is\n",
    "constructed by adding only the other metrics except for the metric under\n",
    "examination, and the RSS of the model that is constructed by adding the\n",
    "other metrics where the metric under examination appears at the last\n",
    "position of the model. For example, given a set of $M$ metrics, and\n",
    "$e,i,j\\in[1,M]$, the importance of each metric $m_e$ can be explained as\n",
    "follows:\n",
    "\n",
    "$$\\mathrm{SS}(m_e) = \\mathrm{RSS}(m_i + ... + m_{j})-\\mathrm{RSS}(m_i + ... + m_{j} + m_e)$$\n",
    "\n",
    "where $m_e$ is the metric under examination and $m_i + ... + m_{j}$ is a\n",
    "set of the other metrics except the metric under examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for Load Data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "# Import for Split Data into Training and Testing Samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset = pd.read_csv((\"../../datasets/lucene-2.9.0.csv\"), index_col = 'File')\n",
    "test_dataset = pd.read_csv((\"../../datasets/lucene-3.0.0.csv\"), index_col = 'File')\n",
    "\n",
    "outcome = 'RealBug'\n",
    "features = ['OWN_COMMIT', 'Added_lines', 'CountClassCoupled', 'AvgLine', 'RatioCommentToCode']\n",
    "\n",
    "# process outcome to 0 and 1\n",
    "train_dataset[outcome] = pd.Categorical(train_dataset[outcome])\n",
    "train_dataset[outcome] = train_dataset[outcome].cat.codes\n",
    "\n",
    "test_dataset[outcome] = pd.Categorical(test_dataset[outcome])\n",
    "test_dataset[outcome] = test_dataset[outcome].cat.codes\n",
    "\n",
    "X_train = train_dataset.loc[:, features]\n",
    "X_test = test_dataset.loc[:, features]\n",
    "\n",
    "y_train = train_dataset.loc[:, outcome]\n",
    "y_test = test_dataset.loc[:, outcome]\n",
    "\n",
    "\n",
    "# commits - # of commits that modify the file of interest\n",
    "# Added lines - # of added lines of code\n",
    "# Count class coupled - # of classes that interact or couple with the class of interest\n",
    "# LOC - # of lines of code\n",
    "# RatioCommentToCode - The ratio of lines of comments to lines of code\n",
    "features = ['nCommit', 'AddedLOC', 'nCoupledClass', 'LOC', 'CommentToCodeRatio']\n",
    "\n",
    "X_train.columns = features\n",
    "X_test.columns = features\n",
    "training_data = pd.concat([X_train, y_train], axis=1)\n",
    "testing_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a black-box model (Regression and Random Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=10, random_state=1234)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for Construct a black-box model (Regression and Random Forests)\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# regression (ols)\n",
    "model_formula = outcome + ' ~ ' + ' + '.join(features)\n",
    "regression_model = ols(model_formula, data = training_data)\n",
    "# regression_model = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "regression_model_fit = regression_model.fit()\n",
    "\n",
    "# regression (logistic regression)\n",
    "lr_model = LogisticRegression(fit_intercept = True)\n",
    "lr_model.fit(X_train, y_train)  \n",
    "\n",
    "# random forests\n",
    "rf_model = RandomForestClassifier(random_state=1234, n_jobs = 10)\n",
    "rf_model.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-release model validation for sanity check (Train with 2.9.0 and test with 3.0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance(model, X_test, y_test):\n",
    "    model_prediction = model.predict_proba(X_test.values)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, model_prediction, pos_label=1)\n",
    "    auc_value = metrics.auc(fpr, tpr)\n",
    "    transformed_prediction = [int(i >= 0.5) for i in model_prediction]\n",
    "    f1_value = metrics.f1_score(y_test, transformed_prediction)\n",
    "    return auc_value, f1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression (AUC, F1): (0.7989602095955461, 0.23236514522821577)\n",
      "Random Forests (AUC, F1): (0.8589023524916761, 0.4951456310679611)\n"
     ]
    }
   ],
   "source": [
    "print('Regression (AUC, F1):', get_model_performance(lr_model, X_test, y_test))\n",
    "print('Random Forests (AUC, F1):', get_model_performance(rf_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for ANOVA (Regression)\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute an ANOVA table\n",
    "aov_table = sm.stats.anova_lm(regression_model_fit, typ=2)\n",
    "aov_table.sort_values(by = 'sum_sq', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize an ANOVA table\n",
    "aov_table['Features'] = aov_table.index\n",
    "aov_table.iloc[1:,:].plot(kind = 'barh', y = 'F', x = 'Features') # remove the residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaitools",
   "language": "python",
   "name": "xaitools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
